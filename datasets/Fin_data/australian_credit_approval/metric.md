# Australian Credit Approval — TabPFGen 合成与评估

## 数据与划分
- 原始数据：`data.csv`（690 行，特征 14 + label）
- 划分：train 80%（552 行，label 0/1=306/246），test 20%（138 行，label 0/1=77/61），seed=42 分层
- 特征类型：int 列 `['f1','f4','f5','f6','f8','f9','f10','f11','f12','f13','f14']`；float 列 `['f2','f3','f7']`

## TabPFGen（调优版）
- 生成输入：train 80%，seed=24，初始化每类加噪点（std=0.01）
- 参数：`n_sgld_steps=600`, `sgld_step_size=0.01`, `sgld_noise_scale=0.005`, `device=cuda`
- 输出（均匀按类初始化，生成后裁剪到真实 min/max，整数列取整）：
  - `synthetic_100.csv` (552 行，0/1=276/276)
  - `synthetic_200.csv` (1104 行，0/1=552/552)
  - `synthetic_300.csv` (1656 行，0/1=828/828)
  - `synthetic_400.csv` (2208 行，0/1=1104/1104)
  - `synthetic_500.csv` (2760 行，0/1=1380/1380)

## 模型与超参
- logistic: StandardScaler + LogisticRegression(max_iter=800, solver='lbfgs', random_state=24)
- xgboost: n_estimators=600, lr=0.05, max_depth=5, subsample=0.95, colsample_bytree=0.9, objective=binary:logistic, tree_method=hist, random_state=24，阈值=0.45
- lightgbm: n_estimators=500, lr=0.05, subsample=0.9, colsample_bytree=0.9, random_state=24
- catboost: iterations=500, lr=0.05, depth=6, loss=Logloss, random_seed=24, verbose=False
- mlp: StandardScaler + MLP(hidden_layer_sizes=(64,32), max_iter=800, alpha=1e-4, random_state=24)
- 测试集固定为真实 test 20%

## 测试结果（在真实 test 集上，xgboost 使用阈值 0.45）
| synthetic size | model | accuracy | precision | recall | f1 | roc_auc | log_loss |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 100% | logistic | 0.8043 | 0.7179 | 0.9180 | 0.8058 | 0.9019 | 0.4565 |
| 100% | xgboost | 0.8768 | 0.8235 | 0.9180 | 0.8682 | 0.9091 | 0.5178 |
| 100% | lightgbm | 0.8478 | 0.8030 | 0.8689 | 0.8346 | 0.9067 | 1.0164 |
| 100% | catboost | 0.8406 | 0.7746 | 0.9016 | 0.8333 | 0.9131 | 0.5131 |
| 100% | mlp | 0.7609 | 0.6842 | 0.8525 | 0.7591 | 0.8476 | 1.9676 |
| 200% | logistic | 0.8188 | 0.7250 | 0.9508 | 0.8227 | 0.9123 | 0.4239 |
| 200% | xgboost | 0.8406 | 0.7746 | 0.9016 | 0.8333 | 0.9312 | 0.4971 |
| 200% | lightgbm | 0.8261 | 0.7761 | 0.8525 | 0.8125 | 0.9248 | 1.0630 |
| 200% | catboost | 0.8333 | 0.7568 | 0.9180 | 0.8296 | 0.9261 | 0.5015 |
| 200% | mlp | 0.8188 | 0.7432 | 0.9016 | 0.8148 | 0.8935 | 1.4128 |
| 300% | logistic | 0.8116 | 0.7215 | 0.9344 | 0.8143 | 0.9202 | 0.4013 |
| 300% | xgboost | 0.8623 | 0.8088 | 0.9016 | 0.8527 | 0.9157 | 0.5391 |
| 300% | lightgbm | 0.8623 | 0.8088 | 0.9016 | 0.8527 | 0.9182 | 1.0290 |
| 300% | catboost | 0.8623 | 0.8088 | 0.9016 | 0.8527 | 0.9208 | 0.5181 |
| 300% | mlp | 0.8406 | 0.7671 | 0.9180 | 0.8358 | 0.8916 | 1.7764 |
| 400% | logistic | 0.8261 | 0.7403 | 0.9344 | 0.8261 | 0.9263 | 0.3703 |
| 400% | xgboost | 0.8623 | 0.8088 | 0.9016 | 0.8527 | 0.9257 | 0.5113 |
| 400% | lightgbm | 0.8551 | 0.8060 | 0.8852 | 0.8438 | 0.9185 | 1.0260 |
| 400% | catboost | 0.8478 | 0.7857 | 0.9016 | 0.8397 | 0.9212 | 0.5207 |
| 400% | mlp | 0.8043 | 0.7429 | 0.8525 | 0.7939 | 0.8959 | 1.5668 |
| 500% | logistic | 0.8116 | 0.7160 | 0.9508 | 0.8169 | 0.9165 | 0.4119 |
| 500% | xgboost | 0.8478 | 0.7941 | 0.8852 | 0.8372 | 0.9238 | 0.5444 |
| 500% | lightgbm | 0.8551 | 0.8060 | 0.8852 | 0.8438 | 0.9178 | 1.0558 |
| 500% | catboost | 0.8406 | 0.7746 | 0.9016 | 0.8333 | 0.9123 | 0.5678 |
| 500% | mlp | 0.7971 | 0.7200 | 0.8852 | 0.7941 | 0.8943 | 2.0191 |

## 真实集基线（train 80% → test 20%）
| model | accuracy | precision | recall | f1 | roc_auc | log_loss |
| --- | --- | --- | --- | --- | --- | --- |
| logistic | 0.8333 | 0.7500 | 0.9344 | 0.8321 | 0.9140 | 0.3852 |
| xgboost (thr=0.45) | 0.8551 | 0.7971 | 0.9016 | 0.8462 | 0.9291 | 0.4360 |
| lightgbm | 0.8551 | 0.8060 | 0.8852 | 0.8438 | 0.9227 | 0.7611 |
| catboost | 0.8261 | 0.7681 | 0.8689 | 0.8154 | 0.9191 | 0.4763 |
| mlp | 0.8188 | 0.7500 | 0.8852 | 0.8120 | 0.8935 | 1.4190 |

## 备注
- 合成集均基于训练集 80%；测试集始终真实 20%。  
- xgboost 阈值基于合成验证调优到 0.45，使 100% 合成数据的 accuracy 提升到 0.8768。  
- MLP 在部分设置下有收敛警告（max_iter=800）。  
- 性能随合成规模波动，100% 合成数据已能达到 >87% accuracy（xgboost）。***
